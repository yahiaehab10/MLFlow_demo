# MLFlow Demo Project

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![MLflow](https://img.shields.io/badge/MLflow-2.0+-orange.svg)](https://mlflow.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.68+-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)

A complete **MLOps pipeline** demonstrating production-ready machine learning workflows using MLflow, DagsHub, DVC, and Evidently for experiment tracking, model versioning, and drift detection.

## ğŸš€ Features

- **ğŸ”„ CI/CD Pipeline** - Automated model training and deployment
- **ğŸ“Š Experiment Tracking** - MLflow integration with DagsHub
- **ğŸ—ƒï¸ Data Versioning** - DVC for dataset and artifact management  
- **ğŸ“ˆ Drift Detection** - Evidently-based monitoring and alerts
- **ğŸš€ Model Serving** - FastAPI REST API with interactive docs
- **ğŸ³ Docker Ready** - Containerized deployment

## ğŸ“‹ Table of Contents

- [Quick Start](#-quick-start)
- [API Usage](#-api-usage)
- [Project Structure](#-project-structure)
- [MLOps Pipeline](#-mlops-pipeline)
- [Documentation](#-documentation)
- [Contributing](#-contributing)

## âš¡ Quick Start

### Option 1: Model API (Recommended for Testing)
```bash
# Install and run
pip install -r requirements.txt
python simple_train.py    # Train model (~30 seconds)
python app.py             # Start API server

# Test the API
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"features": [5.1, 3.5, 1.4, 0.2]}'
```

**ğŸŒ Access:** http://localhost:8000 | **ğŸ“š Docs:** http://localhost:8000/docs

### Option 2: Docker Deployment
```bash
docker build -t iris-model-api .
docker run -p 8000:8000 iris-model-api
```

### Option 3: Full MLOps Pipeline
```bash
# Complete pipeline with tracking
dvc repro                 # Run DVC pipeline
# OR
python -m src.pipeline    # Direct execution
```

## ğŸ”Œ API Usage

### Endpoints
- **`GET /`** - API status and welcome
- **`POST /predict`** - Make predictions (iris classification)

### Example Request
```python
import requests

response = requests.post(
    "http://localhost:8000/predict",
    json={"features": [5.1, 3.5, 1.4, 0.2]}
)
print(response.json())
# Output: {"prediction": 0, "probability": 0.95, "class": "setosa"}
```

## ğŸ“ Project Structure

```
MLflow_demo/
â”œâ”€â”€ app.py                    # FastAPI model serving
â”œâ”€â”€ simple_train.py           # Quick model training
â”œâ”€â”€ test_api.py              # API testing suite
â”œâ”€â”€ Dockerfile               # Container configuration
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original datasets (DVC tracked)
â”‚   â”œâ”€â”€ processed/              # Cleaned data
â”‚   â””â”€â”€ drift_baseline/         # Drift reports
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline.py             # End-to-end ML pipeline
â”‚   â”œâ”€â”€ train.py               # Model training with MLflow
â”‚   â”œâ”€â”€ data_preprocessing.py   # Data cleaning
â”‚   â””â”€â”€ drift_detection.py     # Evidently monitoring
â”‚
â”œâ”€â”€ scripts/                 # Utility scripts
â”œâ”€â”€ dvc.yaml                 # Pipeline configuration
â””â”€â”€ requirements.txt
```

## ğŸ”„ MLOps Pipeline

### What It Does
1. **ğŸ“¥ Data Loading** - Iris dataset ingestion
2. **ğŸ§¹ Data Preprocessing** - Cleaning and validation
3. **ğŸ“Š Drift Detection** - Baseline creation and monitoring
4. **ğŸ¤– Model Training** - RandomForest with hyperparameter tracking
5. **ğŸ“ Model Registry** - MLflow model versioning
6. **ğŸ“ˆ Evaluation** - Performance metrics logging

### Tracking & Monitoring
- **ğŸŒ DagsHub MLflow**: [View Experiments](https://dagshub.com/yahiaehab10/MLFlow_demo.mlflow)
- **ğŸ’» Local MLflow**: Run `mlflow ui` â†’ http://localhost:5000
- **ğŸ“Š Drift Reports**: Interactive HTML reports in `data/drift_baseline/`

### Logged Artifacts
- âœ… Model performance metrics (accuracy, precision, recall)
- âœ… Hyperparameters and training configuration  
- âœ… Data drift analysis reports
- âœ… Model artifacts and dependencies

## ğŸ› ï¸ Setup & Configuration

### Prerequisites
- Python 3.11+
- Git
- Docker (optional)
- DagsHub account (for full pipeline)

### Environment Setup
```bash
# Clone repository
git clone https://github.com/yahiaehab10/MLFlow_demo.git
cd MLFlow_demo

# Install dependencies
pip install -r requirements.txt

# Configure DagsHub (optional)
dvc remote modify origin password <your-dagshub-token>
```

## ğŸ§ª Testing

```bash
# Run API tests
python test_api.py

# Test pipeline
dvc repro --dry

# Manual testing
python -c "
import requests
r = requests.post('http://localhost:8000/predict', 
                 json={'features': [5.1, 3.5, 1.4, 0.2]})
print(r.json())
"
```

## ğŸš¨ Troubleshooting

| Issue | Solution |
|-------|----------|
| DVC authentication error | `dvc remote modify origin password <token>` |
| MLflow connection timeout | Check internet connection and DagsHub access |
| Missing dependencies | `pip install -r requirements.txt` |
| Docker build fails | Ensure Docker daemon is running |

## ğŸ“š Documentation

- **[QUICK_START.md](QUICK_START.md)** - Essential commands for immediate use
- **[SERVING_GUIDE.md](SERVING_GUIDE.md)** - Comprehensive deployment guide
- **[MLflow Docs](https://mlflow.org/docs/latest/index.html)** - MLflow reference
- **[DagsHub Tutorial](https://dagshub.com/docs/tutorial/)** - MLOps collaboration

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
